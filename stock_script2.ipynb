{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### top financial sites\n",
    "news_sites_names =[\" Forbes\",\" Bloomberg\",\" Reuters\",\"The Economist\",\" Wall Street Journal\",\" TheStreet\",\" Financial Times\",\" MarketWatch\" , \"Fortune Magazine\" , \"Business Standard\" , \"The Motley Fool\"]\n",
    "\n",
    "### getting user input\n",
    "\n",
    "stock = input(\"enter company name : \")\n",
    "day = input(\"enter the day in DD format : \")\n",
    "month = input(\"enter the day in MM format : \")\n",
    "year = input(\"enter the day in YYYY format : \")\n",
    "date_for_google = month+\"/\"+day+\"/\"+year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting the news headlines\n",
    "\n",
    "news_headlines =[]\n",
    "\n",
    "for i in range(0,11): \n",
    "    search_stock_and_site = stock + \" \" + news_sites_names[i]    \n",
    "    driver = webdriver.Chrome()\n",
    "    site =\"https://www.google.com/\"\n",
    "    driver.get(site)\n",
    "\n",
    "    search_box = driver.find_element(By.NAME,\"q\")\n",
    "    search_box.send_keys(search_stock_and_site)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    WebDriverWait(driver,timeout=3).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"hdtb-tls\"]')))\n",
    "\n",
    "    tool_box = driver.find_element(By.XPATH,'//*[@id=\"hdtb-tls\"]')\n",
    "    tool_box.click()\n",
    "\n",
    "\n",
    "    dropdown_date_menu = driver.find_element(By.XPATH,'//*[@id=\"tn_1\"]/span[1]/g-popup/div[1]')\n",
    "    driver.execute_script(\"arguments[0].click();\",dropdown_date_menu)\n",
    "\n",
    "    custom_range_selector =driver.find_element(By.XPATH,'//*[@id=\"lb\"]/div/g-menu/g-menu-item[7]/div/div/span')\n",
    "    custom_range_selector.click()\n",
    "\n",
    "    from_date = driver.find_element(By.ID,\"OouJcb\")\n",
    "    from_date.send_keys(date_for_google)\n",
    "\n",
    "    to_date = driver.find_element(By.ID,\"rzG2be\")\n",
    "    to_date.send_keys(date_for_google)\n",
    "\n",
    "    go_button = driver.find_element(By.TAG_NAME,\"g-button\")\n",
    "    driver.execute_script(\"arguments[0].click();\",go_button)\n",
    "\n",
    "    news_button = driver.find_element(By.XPATH,'//*[@id=\"hdtb-msb\"]/div[1]/div/div[2]/a')\n",
    "    news_button.click()\n",
    "\n",
    "    try:\n",
    "        news_headline = driver.find_element(By.XPATH,'//*[@id=\"rso\"]/div/div/div[1]/div/div/a/div/div[2]/div[2]')\n",
    "        news_headlines.append(news_headline.text)\n",
    "    except NoSuchElementException:\n",
    "            pass\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting the stock symbol for the company\n",
    "\n",
    "site_for_symbol=\"https://finance.yahoo.com/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(site_for_symbol)\n",
    "\n",
    "search_box_yahoofinance = driver.find_element(By.XPATH,'//*[@id=\"yfin-usr-qry\"]')\n",
    "search_box_yahoofinance.click()\n",
    "search_box_yahoofinance.send_keys(stock)\n",
    "search_box_yahoofinance.send_keys(Keys.RETURN)\n",
    "\n",
    "WebDriverWait(driver,timeout=10).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"myLightboxContainer\"]/section/button[1]'))).click()\n",
    "\n",
    "stock_profile_at_yahoo = driver.find_element(By.XPATH,'//*[@id=\"quote-nav\"]/ul/li[6]/a')\n",
    "\n",
    "stock_profile_url = stock_profile_at_yahoo.get_attribute(\"href\")\n",
    "\n",
    "stock_symbol = stock_profile_url.split('/')[-2]\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting actual price data for the date from alphavantage\n",
    "import requests\n",
    "\n",
    "date_for_alphavantage = year+\"-\"+month+\"-\"+day\n",
    "opening_price =0\n",
    "closing_price =0\n",
    "\n",
    "#getting url\n",
    "alphavantage_request_url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={}&outputsize=full&apikey=0C49WL5S9IQT1Y26\".format(stock_symbol)\n",
    "response = requests.get(alphavantage_request_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json().get('Time Series (Daily)')\n",
    "    if data:\n",
    "        # get the opening and closing prices for the target date\n",
    "        target_data = data.get(date_for_alphavantage)\n",
    "        if target_data:\n",
    "            opening_price = float(target_data.get('1. open'))\n",
    "            closing_price = float(target_data.get('4. close'))\n",
    "    else:\n",
    "        print(f\"No data available for {date_for_alphavantage}\")\n",
    "else:\n",
    "    print(f\"API request failed with status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comparing opening and closing price to check if stock went up or down\n",
    "actual_stock_movement = 0\n",
    "if closing_price>opening_price or closing_price==opening_price:\n",
    "    actual_stock_movement =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating headlines into a data frame\n",
    "\n",
    "headlines_data_frame = pd.DataFrame(news_headlines)\n",
    "\n",
    "### saving the single stock & date query data\n",
    "date_for_files=day+\"_\"+month+\"_\"+year\n",
    "single_company_csv_name = stock+\"_\"+date_for_files+\"_\"+\".csv\"\n",
    "headlines_data_frame.to_csv(single_company_csv_name)\n",
    "\n",
    "### predicting the stock price using the headlines and our model\n",
    "\n",
    "### combining and cleaning the news headlines\n",
    "combined_news = headlines_data_frame.iloc[:,0].str.cat(sep=' ')\n",
    "combined_news.replace(\"[^a-zA-Z]\",\" \")\n",
    "combined_news.lower()\n",
    "\n",
    "### opening count vectoriser\n",
    "with open('countvector.pkl', 'rb') as read_cv:\n",
    "    countvector = pickle.load(read_cv)\n",
    "\n",
    "### opening our model\n",
    "with open('random_forest_classifier.pkl', 'rb') as read_rfc:\n",
    "    random_forest_classifier = pickle.load(read_rfc)\n",
    "\n",
    "### implement Bag of Words using count vectoriser\n",
    "test_data = countvector.transform([combined_news])\n",
    "\n",
    "### predicting using our model\n",
    "predicted_stock_movement = random_forest_classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###converting predicted output to string\n",
    "x=predicted_stock_movement[0]\n",
    "predicted_stock_price=x.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving new collected data to csv's\n",
    "\n",
    "new_row_for_data = {\n",
    "    'date' : date_for_files,\n",
    "    'stock' : stock,\n",
    "    'news' : combined_news,\n",
    "    'opening_price' : opening_price,\n",
    "    'closing_price' : closing_price,\n",
    "    'actual' : actual_stock_movement,\n",
    "    'predicted' : predicted_stock_price\n",
    "}\n",
    "\n",
    "new_row_for_dataset = {\n",
    "    'date' : date_for_files,\n",
    "    'news' : combined_news,\n",
    "    'actual' : actual_stock_movement,\n",
    "    'predicted' : predicted_stock_price\n",
    "}\n",
    "\n",
    "df_data = pd.read_csv(\"new_data.csv\",encoding='ISO-8859-1')\n",
    "df_data=pd.concat([df_data,pd.DataFrame([new_row_for_data])])\n",
    "df_data.to_csv(\"new_data.csv\",index=False)\n",
    "\n",
    "df_dataset = pd.read_csv(\"new_dataset.csv\",encoding='ISO-8859-1')\n",
    "df_dataset=pd.concat([df_dataset,pd.DataFrame([new_row_for_dataset])])\n",
    "df_dataset.to_csv(\"new_dataset.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
